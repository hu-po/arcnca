{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import optax\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Hyperparams:\n",
    "    seed: int = os.environ.get(\"SEED\", 42)\n",
    "    morph: str = os.environ.get(\"MORPH\", \"test\")\n",
    "    compute_backend: str = os.environ.get(\"COMPUTE_BACKEND\", \"oop\")\n",
    "    wandb_entity: str = os.environ.get(\"WANDB_ENTITY\", \"hug\")\n",
    "    wandb_project: str = os.environ.get(\"WANDB_PROJECT\", \"arc-test\")\n",
    "    run_name: str = \"test\"\n",
    "    created_on: str = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    # ---\n",
    "    learning_rate: float = 1e-3\n",
    "    batch_size: int = 64\n",
    "    num_epochs: int = 8\n",
    "    print_every: int = 100\n",
    "    pad_dim_space: int = 30\n",
    "    pad_dim_time: int = 5\n",
    "    pad_value: int = 0\n",
    "    augment_prob: float = 0.5\n",
    "\n",
    "hp = Hyperparams()\n",
    "hp.run_name = f\"{hp.morph}.{hp.compute_backend}.{str(uuid.uuid4())[:6]}\"\n",
    "\n",
    "def load_tasks(challenges_path, solutions_path):\n",
    "    \"\"\" loads in raw dataset from json files, stored in RAM \"\"\"\n",
    "    tasks = []\n",
    "    with open(challenges_path, 'r') as f:\n",
    "        challenges_dict = json.load(f)\n",
    "    print(f\"loading challenges from {challenges_path}, found {len(challenges_dict)} challenges\")\n",
    "    with open(solutions_path, 'r') as f:\n",
    "        solutions_dict = json.load(f)\n",
    "    print(f\"loading solutions from {solutions_path}, found {len(solutions_dict)} solutions\")\n",
    "    for task_id in challenges_dict.keys():\n",
    "        task_train_in = []\n",
    "        task_train_out = []\n",
    "        task_eval_in = []\n",
    "        task_eval_out = []\n",
    "        for pair in challenges_dict[task_id]['train']:\n",
    "            task_train_in.append(pair['input'])\n",
    "            task_train_out.append(pair['output'])\n",
    "        for grid in challenges_dict[task_id]['test']:\n",
    "            task_eval_in.append(grid)\n",
    "        for grid in solutions_dict[task_id]:\n",
    "            task_eval_out.append(grid)\n",
    "        tasks.append((task_train_in, task_train_out, task_eval_in, task_eval_out))\n",
    "    return tasks\n",
    "\n",
    "@jax.jit\n",
    "def pad_space(key, grid, hp: Hyperparams):\n",
    "    # grid is [H, W, C], pick random start position in space based on grid shape\n",
    "    start_h = jax.random.randint(key, minval=0, maxval=hp.pad_dim_space - grid.shape[0])\n",
    "    start_w = jax.random.randint(key, minval=0, maxval=hp.pad_dim_space - grid.shape[1])\n",
    "    return jnp.pad(grid, (\n",
    "        (start_h, hp.pad_dim_space - grid.shape[0] - start_h),\n",
    "        (start_w, hp.pad_dim_space - grid.shape[1] - start_w),\n",
    "        (0, 0)), mode='constant', constant_values=hp.pad_value)\n",
    "\n",
    "@jax.jit\n",
    "def pad_time(key, grid, hp: Hyperparams):\n",
    "    # grid is [H, W, C], pick random start position in time based on grid shape\n",
    "    start_t = jax.random.randint(key, minval=0, maxval=hp.pad_dim_time - grid.shape[0])\n",
    "    return jnp.pad(grid, (\n",
    "        (start_t, hp.pad_dim_time - grid.shape[0] - start_t),\n",
    "        (0, 0),\n",
    "        (0, 0)), mode='constant', constant_values=hp.pad_value)\n",
    "\n",
    "@jax.jit\n",
    "def random_augment(key, grid, hp: Hyperparams):\n",
    "    # rotate and flip in the H and W dimmensions\n",
    "    for aug_func in [jnp.fliplr, jnp.flipud, jnp.rot90]:\n",
    "        _key, _ = jax.random.split(key)\n",
    "        do_aug = jax.random.bernoulli(_key, hp.augment_prob)\n",
    "        grid = jax.lax.cond(do_aug, lambda x: aug_func(x), lambda x: x, grid)\n",
    "    # shuffle the C dimmension\n",
    "    grid = jax.random.permutation(key, grid, axis=2)\n",
    "    return grid\n",
    "\n",
    "@jax.jit\n",
    "def data_loader(key, tasks, hp: Hyperparams, train_mode=True):\n",
    "    num_tasks = tasks.shape[0]\n",
    "    if train_mode:\n",
    "        indices = jax.random.permutation(key, num_tasks)\n",
    "        tasks = tasks[indices]\n",
    "    num_batches = num_tasks // hp.batch_size\n",
    "    for i in range(num_batches):\n",
    "        for j in range(i*hp.batch_size,(i+1)*hp.batch_size):\n",
    "            task_train_in, task_train_out, task_eval_in, task_eval_out = tasks[j]\n",
    "            # load into gpu memory\n",
    "            task_train_in = jnp.array(task_train_in)\n",
    "            task_train_out = jnp.array(task_train_out)\n",
    "            task_eval_in = jnp.array(task_eval_in)\n",
    "            task_eval_out = jnp.array(task_eval_out)\n",
    "            # pad the task grids in space\n",
    "            keys = jax.random.split(key, 4)\n",
    "            task_train_in = jax.vmap(pad_space)(keys, task_train_in)\n",
    "            task_train_out = jax.vmap(pad_space)(keys, task_train_out)\n",
    "            task_eval_in = jax.vmap(pad_space)(keys, task_eval_in)\n",
    "            task_eval_out = jax.vmap(pad_space)(keys, task_eval_out)\n",
    "            # pad the task_train grids in time\n",
    "            task_train_in = jnp.pad(task_train_in, ((0, 0), (0, hp.pad_dim_time), (0, 0)), mode='constant', constant_values=hp.pad_value)\n",
    "\n",
    "\n",
    "\n",
    "            # augmentation\n",
    "            if train_mode:\n",
    "                keys = jax.random.split(key, \n",
    "                augmented_batch = jax.vmap(random_augment)(keys, batch)\n",
    "\n",
    "        yield task_train_in, task_train_out, task_eval_in, task_eval_out\n",
    "\n",
    "def init_params(key, hp: Hyperparams):\n",
    "    # TODO: implement\n",
    "    pass\n",
    "\n",
    "def model(params, task_train_in, task_train_out, task_eval_in, hp: Hyperparams):\n",
    "    # TODO: implement\n",
    "    pass\n",
    "\n",
    "def loss_fn(params, task_eval_out_pred, task_eval_out_targ, hp: Hyperparams):\n",
    "    # TODO: implement\n",
    "    pass\n",
    "\n",
    "def train_step(params, opt_state, task_train_in, task_train_out, task_eval_in, task_eval_out, hp: Hyperparams):\n",
    "    # TODO: implement\n",
    "    pass\n",
    "\n",
    "def valid_step(params, task_eval_in, task_eval_out, hp: Hyperparams):\n",
    "    # TODO: implement\n",
    "    pass\n",
    "\n",
    "print(f\"training run {hp.run_name} with hyperparameters: {hp}\")\n",
    "wandb.login()\n",
    "wandb.init(name=hp.wandb_entity, project=hp.wandb_project, config=hp.__dict__)\n",
    "key = jax.random.PRNGKey(hp.seed)\n",
    "train_dataset = load_tasks(\n",
    "    '/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json',\n",
    "    '/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json',\n",
    ")\n",
    "valid_dataset = load_tasks(\n",
    "    '/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json',\n",
    "    '/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json',\n",
    ")\n",
    "train_gen = data_loader(key, train_dataset, hp, train_mode=True)\n",
    "valid_gen = data_loader(key, valid_dataset, hp, train_mode=False)\n",
    "params = init_params(key, hp)\n",
    "optimizer = optax.adam(hp.learning_rate)\n",
    "opt_state = optimizer.init(params)\n",
    "for epoch in range(hp.num_epochs):\n",
    "    print(f\"epoch {epoch + 1}/{hp.num_epochs}\")\n",
    "    steps_per_epoch = len(train_dataset) // hp.batch_size\n",
    "    step = 0\n",
    "    for step in range(steps_per_epoch):\n",
    "        step += epoch * steps_per_epoch + step + 1\n",
    "        task_train_in, task_train_out, task_eval_in, task_eval_out = next(train_gen)\n",
    "        params, opt_state, train_loss = train_step(params, opt_state, task_train_in, task_train_out, task_eval_in, task_eval_out, hp)\n",
    "        if step % hp.print_every == 0:\n",
    "            print(f\"step {step}/{steps_per_epoch}: loss = {train_loss.item():.4f}\")\n",
    "            wandb.log({\"train_loss\": train_loss.item()}, step=step)\n",
    "    valid_loss, valid_acc = valid_step(params, valid_gen, hp)\n",
    "    print(f'valid_loss: {valid_loss.item():.4f}, valid_acc: {valid_acc.item():.4f}')\n",
    "    wandb.log({\"valid_loss\": valid_loss.item(), \"valid_acc\": valid_acc.item()}, step=step)\n",
    "wandb.finish()\n",
    "\n",
    "\n",
    "\n",
    "submission_challenges_path = '/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json'\n",
    "tasks = []\n",
    "with open(submission_challenges_path, 'r') as f:\n",
    "    challenges_dict = json.load(f)\n",
    "print(f\"loading challenges from {submission_challenges_path}, found {len(challenges_dict)} challenges\")\n",
    "for task_id in challenges_dict.keys():\n",
    "    # TODO: implement\n",
    "    pass\n",
    "\n",
    "with open('submission.json', 'w') as f:\n",
    "    json.dump(predictions, f)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
