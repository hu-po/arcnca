{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import wandb\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Hyperparams:\n",
    "    seed: int = int(os.environ.get(\"SEED\", 42))\n",
    "    morph: str = os.environ.get(\"MORPH\", \"test\")\n",
    "    compute_backend: str = os.environ.get(\"COMPUTE_BACKEND\", \"oop\")\n",
    "    wandb_entity: str = os.environ.get(\"WANDB_ENTITY\", \"hug\")\n",
    "    wandb_project: str = os.environ.get(\"WANDB_PROJECT\", \"arc-test\")\n",
    "    created_on: str = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    # ---\n",
    "    learning_rate: float = 1e-3\n",
    "    batch_size: int = 8\n",
    "    num_epochs: int = 1\n",
    "    print_every: int = 1\n",
    "    pad_dim_space: int = 30\n",
    "    pad_dim_time: int = 5\n",
    "    pad_value: int = 0\n",
    "    num_channels: int = 10\n",
    "    augment_prob: float = 0.5\n",
    "\n",
    "hp = Hyperparams()\n",
    "\n",
    "def load_tasks(challenges_path, solutions_path):\n",
    "    \"\"\" loads in raw dataset from json files, stored in RAM \"\"\"\n",
    "    tasks = []\n",
    "    with open(challenges_path, 'r') as f:\n",
    "        challenges_dict = json.load(f)\n",
    "    print(f\"loading challenges from {challenges_path}, found {len(challenges_dict)} challenges\")\n",
    "    with open(solutions_path, 'r') as f:\n",
    "        solutions_dict = json.load(f)\n",
    "    print(f\"loading solutions from {solutions_path}, found {len(solutions_dict)} solutions\")\n",
    "    for task_id in challenges_dict.keys():\n",
    "        task_train_in = []\n",
    "        task_train_out = []\n",
    "        task_eval_in = []\n",
    "        task_eval_out = []\n",
    "        # there may be multiple training pairs for each task\n",
    "        for pair in challenges_dict[task_id]['train']:\n",
    "            task_train_in.append(pair['input'])\n",
    "            task_train_out.append(pair['output'])\n",
    "        for grid in challenges_dict[task_id]['test']:\n",
    "            task_eval_in.append(grid['input'])\n",
    "        for grid in solutions_dict[task_id]:\n",
    "            task_eval_out.append(grid)\n",
    "        assert len(task_eval_in) == len(task_eval_out)\n",
    "        assert len(task_train_in) == len(task_train_out)\n",
    "        assert len(task_eval_in) == 1\n",
    "        tasks.append((task_train_in, task_train_out, task_eval_in, task_eval_out))\n",
    "    return tasks\n",
    "\n",
    "def pad_space(key, grid_in, grid_out, hp: Hyperparams):\n",
    "    # grids are [T, H, W, C], pick random start position in space based on grid shape\n",
    "    assert grid_in.shape[1] <= hp.pad_dim_space\n",
    "    assert grid_in.shape[2] <= hp.pad_dim_space\n",
    "    assert grid_in.shape[1] == grid_in.shape[2]\n",
    "    assert grid_out is None or grid_out.shape == grid_in.shape\n",
    "    start_h = jax.random.randint(key, minval=0, maxval=hp.pad_dim_space - grid_in.shape[0] + 1)\n",
    "    start_w = jax.random.randint(key, minval=0, maxval=hp.pad_dim_space - grid_in.shape[1] + 1)\n",
    "    pad_width = ((start_h, hp.pad_dim_space - grid_in.shape[0] - start_h),\n",
    "                 (start_w, hp.pad_dim_space - grid_in.shape[1] - start_w),\n",
    "                 (0, 0))\n",
    "    grid_in = jnp.pad(grid_in, pad_width, mode='constant', constant_values=hp.pad_value)\n",
    "    if grid_out is not None:\n",
    "        grid_out = jnp.pad(grid_out, pad_width, mode='constant', constant_values=hp.pad_value)\n",
    "    return grid_in, grid_out, (start_h, start_w)\n",
    "\n",
    "def pad_time(key, grid_in, grid_out, hp: Hyperparams):\n",
    "    # grids are [T, H, W, C], repeat random example in time until T == hp.pad_dim_time\n",
    "    assert grid_in.shape[0] <= hp.pad_dim_time\n",
    "    assert grid_in.shape[1] <= hp.pad_dim_space\n",
    "    assert grid_in.shape[2] <= hp.pad_dim_space\n",
    "    assert grid_in.shape[1] == grid_in.shape[2]\n",
    "    assert grid_out is None or grid_out.shape == grid_in.shape\n",
    "    for _ in range(hp.pad_dim_time - grid_in.shape[0]):\n",
    "        repeat_example_idx = jax.random.randint(key, minval=0, maxval=grid_in.shape[0])\n",
    "        grid_in = jnp.concatenate([grid_in, grid_in[repeat_example_idx][None]], axis=0)\n",
    "        if grid_out is not None:\n",
    "            grid_out = jnp.concatenate([grid_out, grid_out[repeat_example_idx][None]], axis=0)\n",
    "    # shuffle the T dimension\n",
    "    perm = jax.random.permutation(key, hp.pad_dim_time)\n",
    "    grid_in = grid_in[perm]\n",
    "    if grid_out is not None:\n",
    "        grid_out = grid_out[perm]\n",
    "    return grid_in, grid_out\n",
    "\n",
    "augmentations = [jnp.fliplr, jnp.flipud, jnp.rot90]\n",
    "\n",
    "def random_augment(key, grid_in, grid_out, hp: Hyperparams):\n",
    "    assert grid_in.shape == grid_out.shape\n",
    "    assert grid_in.shape == (hp.pad_dim_time, hp.pad_dim_space, hp.pad_dim_space, hp.num_channels)\n",
    "    apply = jax.random.bernoulli(key, hp.augment_prob, shape=(len(augmentations),))\n",
    "    for i, augmentation in enumerate(augmentations):\n",
    "        grid_in = jax.lax.cond(apply[i], augmentation, lambda x: x, grid_in)\n",
    "        if grid_out is not None:\n",
    "            grid_out = jax.lax.cond(apply[i], augmentation, lambda x: x, grid_out)\n",
    "    # shuffle the C dimension\n",
    "    perm = jax.random.permutation(key, hp.num_channels)\n",
    "    grid_in = grid_in[..., perm]\n",
    "    if grid_out is not None:\n",
    "        grid_out = grid_out[..., perm]\n",
    "    return grid_in, grid_out\n",
    "\n",
    "def data_loader(key, tasks, hp: Hyperparams, train_mode=True):\n",
    "    num_tasks = len(tasks)\n",
    "    if train_mode:\n",
    "        indices = jax.random.permutation(key, num_tasks)\n",
    "        tasks = [tasks[idx] for idx in indices]\n",
    "    num_batches = num_tasks // hp.batch_size\n",
    "    key_seq = jax.random.split(key, num_batches)\n",
    "    for i in range(num_batches):\n",
    "        batch_key = key_seq[i]\n",
    "        subkeys = jax.random.split(batch_key, hp.batch_size * 5)\n",
    "        batch_train_in = []\n",
    "        batch_train_out = []\n",
    "        batch_eval_in = []\n",
    "        batch_eval_out = []\n",
    "        for j, subkey in zip(range(i*hp.batch_size, (i+1)*hp.batch_size), subkeys.reshape(hp.batch_size, 5)):\n",
    "            k1, k2, k3, k4, k5 = subkey\n",
    "            task_train_in = jnp.array(tasks[j][0], dtype=jnp.int32)\n",
    "            task_train_out = jnp.array(tasks[j][1], dtype=jnp.int32)\n",
    "            task_eval_in = jnp.array(tasks[j][2], dtype=jnp.int32)\n",
    "            task_eval_out = jnp.array(tasks[j][3], dtype=jnp.int32)\n",
    "            # convert grids to one-hot (channel dimmension)\n",
    "            task_train_in = jax.vmap(lambda x: jax.nn.one_hot(x, hp.num_channels))(task_train_in)\n",
    "            task_train_out = jax.vmap(lambda x: jax.nn.one_hot(x, hp.num_channels))(task_train_out)\n",
    "            task_eval_in = jax.vmap(lambda x: jax.nn.one_hot(x, hp.num_channels))(task_eval_in)\n",
    "            task_eval_out = jax.vmap(lambda x: jax.nn.one_hot(x, hp.num_channels))(task_eval_out)\n",
    "            # pad in time and space\n",
    "            task_train_in, task_train_out, _ = jax.vmap(pad_space, in_axes=(None, 0, 0, None))(k1, task_train_in, task_train_out, hp)\n",
    "            task_train_in, task_train_out = pad_time(k2, task_train_in, task_train_out, hp)\n",
    "            task_eval_in, task_eval_out, _ = jax.vmap(pad_space, in_axes=(None, 0, 0, None))(k3, task_eval_in, task_eval_out, hp)\n",
    "            if train_mode:\n",
    "                task_train_in, task_train_out = jax.vmap(random_augment, in_axes=(None, 0, 0, None))(k4, task_train_in, task_train_out, hp)\n",
    "                task_eval_in, task_eval_out = jax.vmap(random_augment, in_axes=(None, 0, 0, None))(k5, task_eval_in, task_eval_out, hp)\n",
    "            batch_train_in.append(task_train_in)\n",
    "            batch_train_out.append(task_train_out)\n",
    "            batch_eval_in.append(task_eval_in)\n",
    "            batch_eval_out.append(task_eval_out)\n",
    "        task_train_in = jnp.stack(batch_train_in)\n",
    "        assert task_train_in.shape == (hp.batch_size, hp.pad_dim_time, hp.pad_dim_space, hp.pad_dim_space, hp.num_channels)\n",
    "        task_train_out = jnp.stack(batch_train_out)\n",
    "        assert task_train_out.shape == (hp.batch_size, hp.pad_dim_time, hp.pad_dim_space, hp.pad_dim_space, hp.num_channels)\n",
    "        task_eval_in = jnp.stack(batch_eval_in)\n",
    "        assert task_eval_in.shape == (hp.batch_size, 1, hp.pad_dim_space, hp.pad_dim_space, hp.num_channels)\n",
    "        task_eval_out = jnp.stack(batch_eval_out)\n",
    "        assert task_eval_out.shape == (hp.batch_size, 1, hp.pad_dim_space, hp.pad_dim_space, hp.num_channels)\n",
    "        yield task_train_in, task_train_out, task_eval_in, task_eval_out\n",
    "\n",
    "def init_params(key, hp: Hyperparams):\n",
    "    # TODO\n",
    "    return params\n",
    "\n",
    "def model(params, task_train_in, task_train_out, task_eval_in, hp: Hyperparams):\n",
    "    # TODO\n",
    "    return task_eval_out\n",
    "\n",
    "def loss_fn(task_eval_out_pred, task_eval_out_targ, hp: Hyperparams):\n",
    "    # TODO\n",
    "    return loss\n",
    "\n",
    "def train_step(params, opt_state, task_train_in, task_train_out, task_eval_in, task_eval_out, hp: Hyperparams):\n",
    "    def loss_and_grad(params):\n",
    "        task_eval_out_pred = model(params, task_train_in, task_train_out, task_eval_in, hp)\n",
    "        loss = loss_fn(params, task_eval_out_pred, task_eval_out.squeeze(1), hp)\n",
    "        return loss\n",
    "    loss, grads = jax.value_and_grad(loss_and_grad)(params)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state, params)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, opt_state, loss\n",
    "\n",
    "def valid_step(params, valid_gen, hp: Hyperparams):\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    num_batches = 0\n",
    "    for task_train_in, task_train_out, task_eval_in, task_eval_out in valid_gen:\n",
    "        task_eval_out_pred = model(params, task_train_in, task_train_out, task_eval_in, hp)\n",
    "        loss = loss_fn(task_eval_out_pred, task_eval_out, hp)\n",
    "        total_loss += loss\n",
    "        pred_classes = jnp.argmax(task_eval_out_pred, axis=-1)\n",
    "        true_classes = jnp.argmax(task_eval_out.squeeze(1), axis=-1)\n",
    "        acc = jnp.mean(pred_classes == true_classes)\n",
    "        total_acc += acc\n",
    "        num_batches += 1\n",
    "    avg_loss = total_loss / num_batches\n",
    "    avg_acc = total_acc / num_batches\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "print(f\"hyperparameters: {hp}\")\n",
    "wandb.login()\n",
    "wandb.init(\n",
    "    entity=hp.wandb_entity,\n",
    "    project=hp.wandb_project,\n",
    "    name=f\"{hp.morph}.{hp.compute_backend}.{str(uuid.uuid4())[:6]}\",\n",
    "    config=hp.__dict__,\n",
    ")\n",
    "key = jax.random.PRNGKey(hp.seed)\n",
    "train_tasks = load_tasks(\n",
    "    '/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json',\n",
    "    '/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json',\n",
    ")\n",
    "valid_tasks = load_tasks(\n",
    "    '/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json',\n",
    "    '/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json',\n",
    ")\n",
    "params = init_params(key, hp)\n",
    "optimizer = optax.adam(hp.learning_rate)\n",
    "opt_state = optimizer.init(params)\n",
    "for epoch in range(hp.num_epochs):\n",
    "    print(f\"epoch {epoch + 1}/{hp.num_epochs}\")\n",
    "    steps_per_epoch = len(train_tasks) // hp.batch_size\n",
    "    train_gen = data_loader(key, train_tasks, hp, train_mode=True)\n",
    "    for step in range(steps_per_epoch):\n",
    "        task_train_in, task_train_out, task_eval_in, task_eval_out = next(train_gen)\n",
    "        params, opt_state, train_loss = train_step(params, opt_state, task_train_in, task_train_out, task_eval_in, task_eval_out, hp)\n",
    "        if step % hp.print_every == 0:\n",
    "            print(f\"step {step + 1}/{steps_per_epoch}: loss = {train_loss.item():.4f}\")\n",
    "            wandb.log({\"train_loss\": train_loss.item()}, step=step + 1)\n",
    "    valid_gen = data_loader(key, valid_tasks, hp, train_mode=False)\n",
    "    valid_loss, valid_acc = valid_step(params, valid_gen, hp)\n",
    "    print(f'valid_loss: {valid_loss.item():.4f}, valid_acc: {valid_acc.item():.4f}')\n",
    "    wandb.log({\"valid_loss\": valid_loss.item(), \"valid_acc\": valid_acc.item()}, step=(epoch + 1) * steps_per_epoch)\n",
    "wandb.finish()\n",
    "\n",
    "submission_challenges_path = '/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json'\n",
    "predictions = {}\n",
    "with open(submission_challenges_path, 'r') as f:\n",
    "    challenges_dict = json.load(f)\n",
    "print(f\"loading challenges from {submission_challenges_path}, found {len(challenges_dict)} challenges\")\n",
    "for task_id in challenges_dict.keys():\n",
    "    task = challenges_dict[task_id]\n",
    "    task_train_in = []\n",
    "    task_train_out = []\n",
    "    task_eval_in = []\n",
    "    for pair in task['train']:\n",
    "        task_train_in.append(pair['input'])\n",
    "        task_train_out.append(pair['output'])\n",
    "    for grid in task['test']:\n",
    "        task_eval_in.append(grid['input'])\n",
    "    task_eval_in = jnp.array(task_eval_in, dtype=jnp.int32)\n",
    "    task_train_in = jnp.array(task_train_in, dtype=jnp.int32)\n",
    "    task_train_out = jnp.array(task_train_out, dtype=jnp.int32)\n",
    "    task_train_in = jax.vmap(lambda x: jax.nn.one_hot(x, hp.num_channels))(task_train_in)\n",
    "    task_train_out = jax.vmap(lambda x: jax.nn.one_hot(x, hp.num_channels))(task_train_out)\n",
    "    task_eval_in = jax.vmap(lambda x: jax.nn.one_hot(x, hp.num_channels))(task_eval_in)\n",
    "    task_attempt = {}\n",
    "    for attempt_id in range(2):\n",
    "        # use different padding for each attempt\n",
    "        key = jax.random.PRNGKey(attempt_id)\n",
    "        task_train_in, task_train_out = jax.vmap(pad_space, in_axes=(None, 0, 0, None))(key, task_train_in, task_train_out, hp)\n",
    "        task_train_in, task_train_out = pad_time(key, task_train_in, task_train_out, hp)\n",
    "        task_eval_in, _, (start_h, start_w) = jax.vmap(pad_space, in_axes=(None, 0, 0, None))(key, task_eval_in, None, hp)\n",
    "        task_eval_out_pred = model(params, task_train_in, task_train_out, task_eval_in, hp)\n",
    "        # un-pad for submission\n",
    "        grid_out_pred = task_eval_out_pred[0, start_h:start_h+task_eval_in.shape[1], start_w:start_w+task_eval_in.shape[2]]\n",
    "        task_attempt[f\"attempt_{attempt_id}\"] = grid_out_pred.tolist()\n",
    "    predictions[task_id] = task_attempt\n",
    "\n",
    "with open('submission.json', 'w') as f:\n",
    "    json.dump(predictions, f)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
