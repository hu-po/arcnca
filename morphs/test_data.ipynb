{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import psutil\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class BaseConfig:\n",
    "    seed: int = int(os.environ.get(\"SEED\", 42))\n",
    "    # --- data\n",
    "    train_challenges: str = '/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json'\n",
    "    train_solutions: str = '/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json'\n",
    "    valid_challenges: str = '/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json'\n",
    "    valid_solutions: str = '/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json'\n",
    "    num_time_augs: int = 8\n",
    "    num_color_augs: int = 32\n",
    "    # --- logging \n",
    "    morph: str = os.environ.get(\"MORPH\", \"test\")\n",
    "    compute_backend: str = os.environ.get(\"COMPUTE_BACKEND\", \"oop\")\n",
    "    wandb_entity: str = os.environ.get(\"WANDB_ENTITY\", \"hug\")\n",
    "    wandb_project: str = os.environ.get(\"WANDB_PROJECT\", \"arc-test\")\n",
    "    created_on: str = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "def load_tasks(challenges_path: str, solutions_path: str, cfg: BaseConfig):\n",
    "    with open(challenges_path, 'r') as f:\n",
    "        challenges_dict = json.load(f)\n",
    "    print(f\"loading challenges from {challenges_path}, found {len(challenges_dict)} challenges\")\n",
    "    with open(solutions_path, 'r') as f:\n",
    "        solutions_dict = json.load(f)\n",
    "    print(f\"loading solutions from {solutions_path}, found {len(solutions_dict)} solutions\")\n",
    "    \"\"\"\n",
    "    tasks are stored in JSON format. Each JSON file consists of two key-value pairs.\n",
    "    train: a list of two to ten input/output pairs (typically three.) These are used for your algorithm to infer a rule.\n",
    "    test: a list of one to three input/output pairs (typically one.) Your model should apply the inferred rule from the train set and construct an output solution.\n",
    "    \"\"\"\n",
    "    tasks = []\n",
    "    for task_id in challenges_dict.keys():\n",
    "        print(f\"\\t task {task_id}\")\n",
    "        task_train_in = []\n",
    "        task_train_out = []\n",
    "        task_eval_in = []\n",
    "        task_eval_out = []\n",
    "        \"\"\"\n",
    "        a \"grid\" is a rectangular matrix (list of lists) of integers between 0 and 9 (inclusive).\n",
    "        the smallest possible grid size is 1x1 and the largest is 30x30.\n",
    "        0 represents the background color, 1-9 represent the pattern colors.\n",
    "        \"\"\"\n",
    "        for pair in challenges_dict[task_id]['train']:\n",
    "            _task_train_in = np.array(pair['input'], dtype=np.uint8) # store as uint8 to save system memory\n",
    "            _task_train_out = np.array(pair['output'], dtype=np.uint8)\n",
    "            task_train_in.append(_task_train_in)\n",
    "            task_train_out.append(_task_train_out)\n",
    "            print(f\"shape of task_train_in {_task_train_in.shape}\")\n",
    "            print(f\"shape of task_train_out {_task_train_out.shape}\")\n",
    "        for grid in challenges_dict[task_id]['test']:\n",
    "            _task_eval_in = np.array(grid['input'], dtype=np.uint8)\n",
    "            task_eval_in.append(grid['input'])\n",
    "            print(f\"shape of task_eval_in {_task_eval_in.shape}\")\n",
    "        assert task_id in solutions_dict\n",
    "        for grid in solutions_dict[task_id]:\n",
    "            _grid = np.array(grid, dtype=np.uint8)\n",
    "            task_eval_out.append(_grid)\n",
    "            print(f\"shape of task_eval_out {_grid.shape}\")\n",
    "        assert len(task_train_in) == len(task_train_out)\n",
    "        assert len(task_train_in) <= 10 # maximum number of input/output pairs \n",
    "        assert len(task_eval_in) == len(task_eval_out)\n",
    "        assert len(task_eval_in) <= 3 # maximum number of input/output pairs\n",
    "        tasks.append((task_train_in, task_train_out, task_eval_in, task_eval_out))\n",
    "    return tasks\n",
    "\n",
    "def augmentation(tasks, cfg: BaseConfig):\n",
    "    \"\"\"\n",
    "    basic \"spatial\" augmentation of grids: flipping (lr and ud), rotating (90 and 270)\n",
    "    basic \"time\" augmentation of tasks: changing the order of the training pairs\n",
    "    basic \"channel\" augmentation of grids: change the colors used in the grid (except for 0 the background color)\n",
    "    by pre-augmenting the dataset, we increase the size of the dataset on system memory,\n",
    "    since the dataset is small, the tradeoff of less gpu compute at train time is worth it.\n",
    "    \"\"\"\n",
    "    np.random.seed(cfg.seed)\n",
    "    augmented_tasks = []\n",
    "    for task in tasks:\n",
    "        train_in, train_out, eval_in, eval_out = task\n",
    "        augs = [task]  # Start with the original task\n",
    "        spatial_augs = [np.fliplr, np.flipud, lambda x: np.rot90(x, 1), lambda x: np.rot90(x, 3)]\n",
    "        augs.extend([\n",
    "            ([aug(grid) for grid in train_in],\n",
    "             [aug(grid) for grid in train_out],\n",
    "             [aug(grid) for grid in eval_in],\n",
    "             [aug(grid) for grid in eval_out])\n",
    "            for aug in spatial_augs\n",
    "        ])\n",
    "        if len(train_in) > 1:\n",
    "            augs.extend([\n",
    "                ([train_in[i] for i in np.random.permutation(len(train_in))],\n",
    "                 [train_out[i] for i in np.random.permutation(len(train_out))],\n",
    "                 eval_in, eval_out)\n",
    "                for _ in range(cfg.num_time_augs)\n",
    "            ])\n",
    "        for _ in range(cfg.num_color_augs):\n",
    "            color_map = np.arange(10)\n",
    "            np.random.shuffle(color_map[1:])  # keep 0 as background color\n",
    "            augs.append((\n",
    "                [color_map[grid] for grid in train_in],\n",
    "                [color_map[grid] for grid in train_out],\n",
    "                [color_map[grid] for grid in eval_in],\n",
    "                [color_map[grid] for grid in eval_out]\n",
    "            ))\n",
    "        \n",
    "        augmented_tasks.extend(augs)\n",
    "    return augmented_tasks\n",
    "\n",
    "cfg = BaseConfig()\n",
    "\n",
    "def get_memory_usage():\n",
    "    \"\"\"Returns current system memory usage in MB, total memory in MB, and percentage used.\"\"\"\n",
    "    mem = psutil.virtual_memory()\n",
    "    used_memory = mem.used / (1024 * 1024)  # Convert to MB\n",
    "    total_memory = mem.total / (1024 * 1024)  # Convert to MB\n",
    "    percent_used = mem.percent\n",
    "    return used_memory, total_memory, percent_used\n",
    "\n",
    "def print_memory_status(stage: str):\n",
    "    \"\"\"Prints system memory usage and percentage.\"\"\"\n",
    "    used_memory, total_memory, percent_used = get_memory_usage()\n",
    "    print(f\"[{stage}] Memory usage: {used_memory:.2f} MB / {total_memory:.2f} MB ({percent_used:.2f}% used)\")\n",
    "\n",
    "def print_array_size(arr, name):\n",
    "    \"\"\"Prints the size of a Numpy array in bytes.\"\"\"\n",
    "    size = sys.getsizeof(arr)\n",
    "    print(f\"Array {name} has size {size} bytes, shape {arr.shape}, dtype {arr.dtype}\")\n",
    "\n",
    "# Memory usage reporting and task loading\n",
    "print_memory_status(\"Before loading tasks\")\n",
    "train_tasks = load_tasks(cfg.train_challenges, cfg.train_solutions, cfg)\n",
    "valid_tasks = load_tasks(cfg.valid_challenges, cfg.valid_solutions, cfg)\n",
    "print_memory_status(\"After loading tasks\")\n",
    "\n",
    "# Augmentation\n",
    "train_tasks = augmentation(train_tasks, cfg)\n",
    "print(f\"Augmented train tasks: {len(train_tasks)}\")\n",
    "print_memory_status(\"After augmenting train tasks\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
