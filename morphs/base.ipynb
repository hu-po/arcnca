{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'pytest>=8.3.2' 'numpy>=1.26.4' 'pillow>=10.4.0' 'msgpack>=1.1.0' 'requests>=2.32.3' 'mediapy>=1.2.2' tqdm\n",
    "!pip install --no-deps 'optax==0.2.3' 'chex==0.1.86' 'flax>=0.9.0' orbax-checkpoint tensorstore 'typing-extensions>=4.2' 'absl-py>=2.1.0' 'toolz>=1.0.0' 'etils[epy]>=1.9.4'\n",
    "!pip install wandb\n",
    "!wandb login\n",
    "!git clone https://github.com/hu-po/cax.git /cax\n",
    "!pip install --upgrade /cax --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import jax\n",
    "import jaxlib\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import wandb\n",
    "\n",
    "import flax\n",
    "from flax import nnx\n",
    "import optax\n",
    "import cax\n",
    "\n",
    "for pkg in [jax, jaxlib, cax, flax, optax]:\n",
    "    print(pkg.__name__, pkg.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph =  os.environ[\"MORPH\"]\n",
    "morph_nb_filepath =  os.environ[\"MORPH_NB_FILEPATH\"]\n",
    "morph_output_dir =  os.environ[\"MORPH_OUTPUT_DIR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(path):\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "train_challenges = load_data('/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json')\n",
    "train_solutions = load_data('/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json')\n",
    "eval_challenges = load_data('/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json')\n",
    "eval_solutions = load_data('/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json')\n",
    "\n",
    "# Process tasks\n",
    "def process_tasks(challenges, solutions):\n",
    "    data = []\n",
    "    task_id_to_index = {}\n",
    "    for index, task_id in enumerate(challenges.keys()):\n",
    "        task_id_to_index[task_id] = index\n",
    "        task = challenges[task_id]\n",
    "        solution = solutions[task_id]\n",
    "        for pair in task['train']:\n",
    "            input_grid = np.array(pair['input'], dtype=np.int32)\n",
    "            output_grid = np.array(pair['output'], dtype=np.int32)\n",
    "            data.append((input_grid, output_grid, index))\n",
    "        for i, test_input in enumerate(task['test']):\n",
    "            input_grid = np.array(test_input['input'], dtype=np.int32)\n",
    "            output_grid = np.array(solution[i], dtype=np.int32)\n",
    "            data.append((input_grid, output_grid, index))\n",
    "    return data, task_id_to_index\n",
    "\n",
    "# Pad grid function\n",
    "def pad_grid(grid, max_size=30, pad_value=0, center_offset=(0, 0)):\n",
    "    padded = np.full((max_size, max_size), pad_value, dtype=np.int32)\n",
    "    rows, cols = grid.shape\n",
    "    offset_row = (max_size - rows) // 2 + center_offset[0]\n",
    "    offset_col = (max_size - cols) // 2 + center_offset[1]\n",
    "    offset_row = np.clip(offset_row, 0, max_size - rows)\n",
    "    offset_col = np.clip(offset_col, 0, max_size - cols)\n",
    "    padded[offset_row:offset_row+rows, offset_col:offset_col+cols] = grid\n",
    "    return padded\n",
    "\n",
    "# Augmentation functions using JAX\n",
    "@jax.jit\n",
    "def flip_horizontal(grid):\n",
    "    return jnp.fliplr(grid)\n",
    "\n",
    "@jax.jit\n",
    "def flip_vertical(grid):\n",
    "    return jnp.flipud(grid)\n",
    "\n",
    "@partial(jax.jit, static_argnums=(1,))\n",
    "def rotate(grid, k):\n",
    "    return jnp.rot90(grid, k=k)\n",
    "\n",
    "AUGMENTATIONS = {\n",
    "    'flip_horizontal': flip_horizontal,\n",
    "    'flip_vertical': flip_vertical,\n",
    "    'rotate_90': partial(rotate, k=1),\n",
    "    'rotate_180': partial(rotate, k=2),\n",
    "    'rotate_270': partial(rotate, k=3),\n",
    "}\n",
    "\n",
    "# Apply random augmentations to a batch\n",
    "def apply_random_augmentations_batch(input_grids, output_grids, rng_keys, augmentations):\n",
    "    num_augs = len(augmentations)\n",
    "\n",
    "    def augment_sample(input_grid, output_grid, rng_key):\n",
    "        apply_aug = jax.random.bernoulli(rng_key, p=0.5, shape=(num_augs,))\n",
    "        for i, aug_name in enumerate(augmentations):\n",
    "            aug_func = AUGMENTATIONS[aug_name]\n",
    "            input_grid, output_grid = jax.lax.cond(\n",
    "                apply_aug[i],\n",
    "                lambda grids: (aug_func(grids[0]), aug_func(grids[1])),\n",
    "                lambda grids: grids,\n",
    "                (input_grid, output_grid)\n",
    "            )\n",
    "        return input_grid, output_grid\n",
    "\n",
    "    # Vectorize over the batch dimension\n",
    "    v_augment_sample = jax.vmap(augment_sample, in_axes=(0, 0, 0), out_axes=(0, 0))\n",
    "    augmented_inputs, augmented_outputs = v_augment_sample(input_grids, output_grids, rng_keys)\n",
    "    return augmented_inputs, augmented_outputs\n",
    "\n",
    "# Data generator\n",
    "def data_generator(data, batch_size, augmentations=None, max_size=30, pad_value=0, center_offset=(0, 0), shuffle=True):\n",
    "    num_samples = len(data)\n",
    "    indices = np.arange(num_samples)\n",
    "    epoch = 0\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            rng = np.random.default_rng(seed=epoch)\n",
    "            rng.shuffle(indices)\n",
    "        for start_idx in range(0, num_samples, batch_size):\n",
    "            excerpt = indices[start_idx:start_idx + batch_size]\n",
    "            batch_inputs = []\n",
    "            batch_outputs = []\n",
    "            batch_task_indices = []\n",
    "            for idx in excerpt:\n",
    "                input_grid, output_grid, task_index = data[idx]\n",
    "                input_padded = pad_grid(input_grid, max_size, pad_value, center_offset)\n",
    "                output_padded = pad_grid(output_grid, max_size, pad_value, center_offset)\n",
    "                batch_inputs.append(input_padded)\n",
    "                batch_outputs.append(output_padded)\n",
    "                batch_task_indices.append(task_index)\n",
    "            batch_inputs = jnp.stack(batch_inputs)\n",
    "            batch_outputs = jnp.stack(batch_outputs)\n",
    "            batch_task_indices = jnp.array(batch_task_indices, dtype=jnp.int32)\n",
    "            if augmentations:\n",
    "                rng_key = jax.random.PRNGKey(epoch)\n",
    "                rng_key = jax.random.fold_in(rng_key, start_idx)\n",
    "                rng_keys = jax.random.split(rng_key, len(batch_inputs))\n",
    "                batch_inputs, batch_outputs = apply_random_augmentations_batch(batch_inputs, batch_outputs, rng_keys, augmentations)\n",
    "            yield batch_inputs, batch_outputs, batch_task_indices\n",
    "        epoch += 1\n",
    "\n",
    "train_data, task_id_to_index = process_tasks(train_challenges, train_solutions)\n",
    "eval_data, _ = process_tasks(eval_challenges, eval_solutions)\n",
    "\n",
    "augmentations = ['flip_horizontal', 'flip_vertical', 'rotate_90', 'rotate_180', 'rotate_270']\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = data_generator(train_data, batch_size, augmentations=augmentations)\n",
    "eval_generator = data_generator(eval_data, batch_size, augmentations=None, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<code>\n",
    "# Define a training step function\n",
    "@jax.jit\n",
    "def train_step(params, batch_inputs, batch_outputs, batch_task_indices, opt_state):\n",
    "    def loss_fn(params):\n",
    "        preds = model.apply(params, batch_inputs)\n",
    "        loss = compute_loss(preds, batch_outputs)\n",
    "        return loss\n",
    "    grads = jax.grad(loss_fn)(params)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, opt_state\n",
    "\n",
    "# Assuming you have defined your model, loss function, and optimizer\n",
    "# Initialize model parameters and optimizer state\n",
    "params = model.init(jax.random.PRNGKey(0), jnp.ones((batch_size, 30, 30)))\n",
    "opt_state = optimizer.init(params)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "steps_per_epoch = len(train_data) // batch_size\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    for step in range(steps_per_epoch):\n",
    "        batch_inputs, batch_outputs, batch_task_indices = next(train_generator)\n",
    "        # Your training code here\n",
    "        # For example: params, opt_state = train_step(params, batch_inputs, batch_outputs, batch_task_indices, opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_challenges_path = '/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json'\n",
    "prepare_submission(ca, test_challenges_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
