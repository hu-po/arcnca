{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'pytest>=8.3.2' 'numpy>=1.26.4' 'pillow>=10.4.0' 'msgpack>=1.1.0' 'requests>=2.32.3' 'mediapy>=1.2.2' tqdm\n",
    "!pip install --no-deps 'optax==0.2.3' 'chex==0.1.86' 'flax>=0.9.0' orbax-checkpoint tensorstore 'typing-extensions>=4.2' 'absl-py>=2.1.0' 'toolz>=1.0.0' 'etils[epy]>=1.9.4'\n",
    "!git clone https://github.com/hu-po/cax.git /cax\n",
    "!pip install --upgrade /cax --no-deps\n",
    "!pytest --color=no /cax/tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import jax\n",
    "import jaxlib\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import flax\n",
    "from flax import nnx\n",
    "import optax\n",
    "import cax\n",
    "\n",
    "for pkg in [jax, jaxlib, cax, flax, optax]:\n",
    "    print(pkg.__name__, pkg.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import mediapy\n",
    "import optax\n",
    "from cax.core.ca import CA\n",
    "from cax.core.perceive.depthwise_conv_perceive import DepthwiseConvPerceive\n",
    "from cax.core.perceive.kernels import grad_kernel, identity_kernel\n",
    "from cax.core.state import state_from_rgba_to_rgb, state_to_rgba\n",
    "from cax.core.update.nca_update import NCAUpdate\n",
    "from cax.utils.image import get_emoji\n",
    "from flax import nnx\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Configuration\n",
    "seed = 0\n",
    "channel_size = 16\n",
    "num_kernels = 3\n",
    "hidden_size = 128\n",
    "cell_dropout_rate = 0.5\n",
    "batch_size = 8\n",
    "num_steps = 64\n",
    "learning_rate = 1e-3\n",
    "\n",
    "emoji = \"ðŸ¦Ž\"\n",
    "target_size = 40\n",
    "target_padding = 16\n",
    "\n",
    "key = jax.random.PRNGKey(seed)\n",
    "rngs = nnx.Rngs(seed)\n",
    "\n",
    "# Dataset\n",
    "target = get_emoji(emoji, size=target_size, padding=target_padding)\n",
    "mediapy.show_image(target)\n",
    "\n",
    "# Init state\n",
    "def add_noise(target, alpha, key):\n",
    "    noise = jax.random.normal(key, target.shape)\n",
    "    noisy_image = (1 - alpha) * target + alpha * noise\n",
    "    return jnp.clip(noisy_image, 0.0, 1.0)\n",
    "\n",
    "def init_state(key):\n",
    "    state = jnp.zeros(target.shape[:2] + (channel_size,))\n",
    "    alpha_key, noise_key = jax.random.split(key)\n",
    "    alpha = jax.random.uniform(alpha_key)\n",
    "    noise = jax.random.normal(noise_key, target.shape)\n",
    "    noisy_target = (1 - alpha) * target + alpha * noise\n",
    "    return state.at[..., -4:].set(noisy_target)\n",
    "\n",
    "# Model\n",
    "perceive = DepthwiseConvPerceive(channel_size, rngs)\n",
    "update = NCAUpdate(channel_size, num_kernels * channel_size, (hidden_size,), rngs, cell_dropout_rate=cell_dropout_rate)\n",
    "kernel = jnp.concatenate([identity_kernel(ndim=2), grad_kernel(ndim=2)], axis=-1)\n",
    "kernel = jnp.expand_dims(jnp.concatenate([kernel] * channel_size, axis=-1), axis=-2)\n",
    "perceive.depthwise_conv.kernel = nnx.Param(kernel)\n",
    "ca = CA(perceive, update)\n",
    "params = nnx.state(ca, nnx.Param)\n",
    "print(\"Number of params:\", jax.tree.reduce(lambda x, y: x + y.size, params, 0))\n",
    "\n",
    "# Optimizer\n",
    "lr_sched = optax.linear_schedule(init_value=learning_rate, end_value=0.1 * learning_rate, transition_steps=2_000)\n",
    "optimizer = optax.chain(\n",
    "    optax.clip_by_global_norm(1.0),\n",
    "    optax.adam(learning_rate=lr_sched),\n",
    ")\n",
    "update_params = nnx.All(nnx.Param, nnx.PathContains(\"update\"))\n",
    "optimizer = nnx.Optimizer(ca, optimizer, wrt=update_params)\n",
    "\n",
    "# Loss\n",
    "def mse(state):\n",
    "    return jnp.mean(jnp.square(state_to_rgba(state) - target))\n",
    "\n",
    "@nnx.jit\n",
    "def loss_fn(ca, state):\n",
    "    state_axes = nnx.StateAxes({nnx.RngState: 0, ...: None})\n",
    "    state = nnx.split_rngs(splits=batch_size)(\n",
    "        nnx.vmap(\n",
    "            lambda ca, state: ca(state, num_steps=num_steps, all_steps=True),\n",
    "            in_axes=(state_axes, 0),\n",
    "        )\n",
    "    )(ca, state)\n",
    "    loss = mse(state)\n",
    "    return loss\n",
    "\n",
    "# Train step\n",
    "@nnx.jit\n",
    "def train_step(ca, optimizer, key):\n",
    "    keys = jax.random.split(key, batch_size)\n",
    "    current_state = jax.vmap(init_state)(keys)\n",
    "    loss, grad = nnx.value_and_grad(loss_fn, argnums=nnx.DiffState(0, update_params))(ca, current_state)\n",
    "    optimizer.update(grad)\n",
    "    return loss\n",
    "\n",
    "# Main loop\n",
    "num_train_steps = 8_192\n",
    "print_interval = 128\n",
    "pbar = tqdm(range(num_train_steps), desc=\"Training\", unit=\"train_step\")\n",
    "losses = []\n",
    "\n",
    "for i in pbar:\n",
    "    key, subkey = jax.random.split(key)\n",
    "    loss = train_step(ca, optimizer, subkey)\n",
    "    losses.append(loss)\n",
    "    if i % print_interval == 0 or i == num_train_steps - 1:\n",
    "        avg_loss = sum(losses[-print_interval:]) / len(losses[-print_interval:])\n",
    "        pbar.set_postfix({\"Average Loss\": f\"{avg_loss:.6f}\"})\n",
    "\n",
    "# Visualize\n",
    "key, subkey = jax.random.split(key)\n",
    "keys = jax.random.split(subkey, 8)\n",
    "state = jax.vmap(init_state)(keys)\n",
    "state_axes = nnx.StateAxes({nnx.RngState: 0, ...: None})\n",
    "state = nnx.split_rngs(splits=8)(\n",
    "    nnx.vmap(\n",
    "        lambda ca, state: ca(state, num_steps=2 * num_steps, all_steps=True),\n",
    "        in_axes=(state_axes, 0),\n",
    "    )\n",
    ")(ca, state)\n",
    "mediapy.show_images(state_to_rgba(state[:, -1]), width=128, height=128)\n",
    "mediapy.show_videos(state_from_rgba_to_rgb(state), width=128, height=128, codec=\"gif\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
