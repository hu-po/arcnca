{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'pytest>=8.3.2' 'numpy>=1.26.4' 'pillow>=10.4.0' 'msgpack>=1.1.0' 'requests>=2.32.3' 'mediapy>=1.2.2' tqdm\n",
    "!pip install --no-deps 'optax==0.2.3' 'chex==0.1.86' 'flax>=0.9.0' orbax-checkpoint tensorstore 'typing-extensions>=4.2' 'absl-py>=2.1.0' 'toolz>=1.0.0' 'etils[epy]>=1.9.4'\n",
    "# !pip install wandb\n",
    "!git clone https://github.com/hu-po/cax.git /cax\n",
    "!pip install --upgrade /cax --no-deps\n",
    "!pytest --color=no /cax/tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import jax\n",
    "import jaxlib\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "# import wandb\n",
    "\n",
    "import flax\n",
    "from flax import nnx\n",
    "import optax\n",
    "import cax\n",
    "from cax.core.ca import CA\n",
    "from cax.core.perceive.depthwise_conv_perceive import DepthwiseConvPerceive\n",
    "from cax.core.perceive.kernels import grad_kernel, identity_kernel\n",
    "from cax.core.update.residual_update import ResidualUpdate\n",
    "\n",
    "for pkg in [jax, jaxlib, cax, flax, optax]:\n",
    "    print(pkg.__name__, pkg.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    print(f\"Loaded {len(data)} tasks from {path}\")\n",
    "    return data\n",
    "\n",
    "train_challenges = load_data('/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json')\n",
    "train_solutions = load_data('/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json')\n",
    "eval_challenges = load_data('/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json')\n",
    "eval_solutions = load_data('/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json')\n",
    "\n",
    "def process_tasks(challenges, solutions):\n",
    "    inputs, outputs, task_indices = [], [], []\n",
    "    task_id_to_index = {}\n",
    "    for index, task_id in enumerate(challenges.keys()):\n",
    "        task_id_to_index[task_id] = index\n",
    "        task = challenges[task_id]\n",
    "        solution = solutions[task_id]\n",
    "        for pair in task['train']:\n",
    "            inputs.append(np.array(pair['input'], dtype=np.int32))\n",
    "            outputs.append(np.array(pair['output'], dtype=np.int32))\n",
    "            task_indices.append(index)\n",
    "        for i, test_input in enumerate(task['test']):\n",
    "            inputs.append(np.array(test_input['input'], dtype=np.int32))\n",
    "            outputs.append(np.array(solution[i], dtype=np.int32))\n",
    "            task_indices.append(index)\n",
    "    return inputs, outputs, task_indices, task_id_to_index\n",
    "\n",
    "def pad_grids(grids, max_size=30, pad_value=0):\n",
    "    padded_grids = []\n",
    "    for grid in grids:\n",
    "        padded = np.full((max_size, max_size), pad_value, dtype=np.int32)\n",
    "        rows, cols = grid.shape\n",
    "        padded[:rows, :cols] = grid\n",
    "        padded_grids.append(padded)\n",
    "    return np.stack(padded_grids)\n",
    "\n",
    "def prepare_data(challenges, solutions):\n",
    "    inputs, outputs, task_indices, task_id_to_index = process_tasks(challenges, solutions)\n",
    "    print(f\"\\t number of samples: {len(inputs)}\")\n",
    "    inputs_array = pad_grids(inputs)\n",
    "    outputs_array = pad_grids(outputs)\n",
    "    task_indices_array = np.array(task_indices, dtype=np.int32)\n",
    "    inputs_array = jnp.array(inputs_array)\n",
    "    outputs_array = jnp.array(outputs_array)\n",
    "    task_indices_array = jnp.array(task_indices_array)\n",
    "    return inputs_array, outputs_array, task_indices_array, task_id_to_index\n",
    "\n",
    "print(\"Processing train data...\")\n",
    "train_inputs, train_outputs, train_task_indices, task_id_to_index = prepare_data(train_challenges, train_solutions)\n",
    "print(f\"\\t inputs shape: {train_inputs.shape}\")\n",
    "print(f\"\\t outputs shape: {train_outputs.shape}\")\n",
    "print(f\"\\t task indices shape: {train_task_indices.shape}\")\n",
    "\n",
    "print(\"Processing eval data...\")\n",
    "eval_inputs, eval_outputs, eval_task_indices, _ = prepare_data(eval_challenges, eval_solutions)\n",
    "print(f\"\\t inputs shape: {eval_inputs.shape}\")\n",
    "print(f\"\\t outputs shape: {eval_outputs.shape}\")\n",
    "print(f\"\\t task indices shape: {eval_task_indices.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_training_params(test_mode=True):\n",
    "    if test_mode:\n",
    "        batch_size = 2\n",
    "        num_steps = 2\n",
    "        num_train_steps = 2\n",
    "        print_interval = 1\n",
    "    else:\n",
    "        batch_size = 16\n",
    "        num_steps = 12\n",
    "        num_train_steps = 1000\n",
    "        print_interval = 50\n",
    "    return batch_size, num_steps, num_train_steps, print_interval\n",
    "\n",
    "TEST_MODE = True\n",
    "batch_size, num_steps, num_train_steps, print_interval = set_training_params(TEST_MODE)\n",
    "\n",
    "seed = 0\n",
    "key = jax.random.PRNGKey(seed)\n",
    "rngs = nnx.Rngs(seed)\n",
    "\n",
    "channel_size = 32\n",
    "num_kernels = 2\n",
    "hidden_size = 256\n",
    "cell_dropout_rate = 0.5\n",
    "learning_rate = 1e-3\n",
    "ds_size = 30\n",
    "\n",
    "num_tasks = len(task_id_to_index)\n",
    "print(f\"Number of tasks: {num_tasks}\")\n",
    "\n",
    "# Define the NCA model\n",
    "class EmbedCA(CA):\n",
    "    embed_input: nnx.Embed\n",
    "    embed_task: nnx.Embed\n",
    "\n",
    "    def __init__(self, perceive, update, embed_input, embed_task):\n",
    "        super().__init__(perceive, update)\n",
    "        self.embed_input = embed_input\n",
    "        self.embed_task = embed_task\n",
    "\n",
    "    def __call__(self, state, task_embed, num_steps=1, all_steps=False):\n",
    "        steps = []\n",
    "        for _ in range(num_steps):\n",
    "            state = self.step(state, task_embed)\n",
    "            if all_steps:\n",
    "                steps.append(state)\n",
    "        if all_steps:\n",
    "            return jnp.stack(steps)\n",
    "        else:\n",
    "            return state\n",
    "\n",
    "\n",
    "def init_state(inputs, outputs, task_indices, key):\n",
    "    idx = jax.random.randint(key, (), 0, inputs.shape[0])\n",
    "    input_grid = inputs[idx]\n",
    "    target_grid = outputs[idx]\n",
    "    task_index = task_indices[idx]\n",
    "    state = jnp.zeros((ds_size, ds_size, channel_size))\n",
    "    state = state.at[..., 0].set(input_grid)\n",
    "    return state, target_grid, task_index\n",
    "\n",
    "def init_nca_model():\n",
    "    perceive = DepthwiseConvPerceive(channel_size, rngs, num_kernels=num_kernels, kernel_size=(3, 3))\n",
    "    update = ResidualUpdate(\n",
    "        num_spatial_dims=2,\n",
    "        channel_size=channel_size,\n",
    "        input_size=num_kernels * channel_size + 8,\n",
    "        hidden_sizes=(hidden_size,),\n",
    "        rngs=rngs,\n",
    "        cell_dropout_rate=cell_dropout_rate,\n",
    "    )\n",
    "    embed_input = nnx.Embed(num_embeddings=10, features=3, rngs=rngs)\n",
    "    embed_task = nnx.Embed(num_embeddings=num_tasks, features=8, rngs=rngs)\n",
    "    ca = EmbedCA(perceive, update, embed_input, embed_task)\n",
    "    return ca\n",
    "\n",
    "ca = init_nca_model()\n",
    "\n",
    "identity = identity_kernel(ndim=2)\n",
    "gradient = grad_kernel(ndim=2)\n",
    "base_kernel = jnp.concatenate([identity, gradient], axis=-1)\n",
    "base_kernel = base_kernel[:, :, None, :]\n",
    "features = channel_size * num_kernels\n",
    "tiles = int(np.ceil(features / base_kernel.shape[-1]))\n",
    "kernel = jnp.tile(base_kernel, (1, 1, 1, tiles))\n",
    "kernel = kernel[:, :, :, :features]\n",
    "ca.perceive.depthwise_conv.kernel = nnx.Param(kernel)\n",
    "params = nnx.state(ca, nnx.Param)\n",
    "\n",
    "def init_optimizer(ca):\n",
    "    lr_sched = optax.linear_schedule(init_value=learning_rate, end_value=0.1 * learning_rate, transition_steps=2000)\n",
    "    optimizer = optax.chain(\n",
    "        optax.clip_by_global_norm(1.0),\n",
    "        optax.adam(learning_rate=lr_sched),\n",
    "    )\n",
    "    update_params = nnx.All(nnx.Param, nnx.PathContains(\"update\"))\n",
    "    optimizer = nnx.Optimizer(ca, optimizer, wrt=update_params)\n",
    "    return optimizer, update_params\n",
    "\n",
    "optimizer, update_params = init_optimizer(ca)\n",
    "\n",
    "def mse(state, target):\n",
    "    return jnp.mean(jnp.square(state[..., :3] - target))\n",
    "\n",
    "@nnx.jit\n",
    "def accuracy_fn(state, target):\n",
    "    predictions = jnp.argmax(state[..., :3], axis=-1)\n",
    "    correct = jnp.sum(predictions == target)\n",
    "    total = target.size\n",
    "    return correct / total\n",
    "\n",
    "@nnx.jit\n",
    "def loss_fn(ca, state, target, task_index):\n",
    "    input_grid = state[..., 0]\n",
    "    input_embed = ca.embed_input(jnp.asarray(input_grid, dtype=jnp.int32))\n",
    "    task_embed = ca.embed_task(jnp.asarray(task_index, dtype=jnp.int32))\n",
    "    state = state.at[..., :3].set(input_embed)\n",
    "    target_embed = ca.embed_input(jnp.asarray(target, dtype=jnp.int32))\n",
    "    state_axes = nnx.StateAxes({nnx.RngState: 0, ...: None})\n",
    "    state = nnx.split_rngs(splits=batch_size)(\n",
    "        nnx.vmap(\n",
    "            lambda ca, state, task_embed: ca(state, task_embed, num_steps=num_steps),\n",
    "            in_axes=(state_axes, 0, 0),\n",
    "        )\n",
    "    )(ca, state, task_embed)\n",
    "    loss = mse(state, target_embed)\n",
    "    return loss\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(ca, optimizer, key):\n",
    "    keys = jax.random.split(key, batch_size)\n",
    "    state, target, task_index = jax.vmap(lambda k: init_state(train_inputs, train_outputs, train_task_indices, k))(keys)\n",
    "    loss, grad = nnx.value_and_grad(loss_fn, argnums=nnx.DiffState(0, update_params))(ca, state, target, task_index)\n",
    "    optimizer.update(grad)\n",
    "    return loss\n",
    "\n",
    "@nnx.jit\n",
    "def eval_step(ca, key):\n",
    "    keys = jax.random.split(key, batch_size)\n",
    "    state, target, task_index = jax.vmap(lambda k: init_state(eval_inputs, eval_outputs, eval_task_indices, k))(keys)\n",
    "    accuracy = accuracy_fn(state, target)\n",
    "    return accuracy\n",
    "\n",
    "pbar = tqdm(range(num_train_steps), desc=\"Training\", unit=\"step\")\n",
    "losses = []\n",
    "eval_accuracies = []\n",
    "\n",
    "for i in pbar:\n",
    "    key, subkey = jax.random.split(key)\n",
    "    loss = train_step(ca, optimizer, subkey)\n",
    "    losses.append(loss)\n",
    "\n",
    "    if i % print_interval == 0 or i == num_train_steps - 1:\n",
    "        avg_loss = sum(losses[-print_interval:]) / len(losses[-print_interval:])\n",
    "        pbar.set_postfix({\"Avg Loss\": f\"{avg_loss:.6f}\"})\n",
    "        accuracy = eval_step(ca, subkey)\n",
    "        eval_accuracies.append(accuracy)\n",
    "        avg_accuracy = sum(eval_accuracies[-print_interval:]) / len(eval_accuracies[-print_interval:])\n",
    "        print(f\"Step {i}, Avg Loss: {avg_loss:.6f}, Eval Acc: {avg_accuracy:.4f}\")\n",
    "\n",
    "def prepare_submission(ca, test_challenges_path):\n",
    "    with open(test_challenges_path, 'r') as f:\n",
    "        test_challenges = json.load(f)\n",
    "\n",
    "    submission = {}\n",
    "    for task_id, task in test_challenges.items():\n",
    "        test_pairs = task['test']\n",
    "        outputs = []\n",
    "        for test_input in test_pairs:\n",
    "            input_grid = np.array(test_input['input'], dtype=np.int32)\n",
    "            padded_input = pad_grids([input_grid])[0]\n",
    "            state = np.zeros((ds_size, ds_size, channel_size), dtype=np.float32)\n",
    "            state[..., 0] = padded_input\n",
    "            input_embed = ca.embed_input(jnp.asarray(state[..., 0], dtype=jnp.int32))\n",
    "            task_index = task_id_to_index.get(task_id, 0)\n",
    "            task_embed = ca.embed_task(jnp.asarray(task_index, dtype=jnp.int32))\n",
    "            state = jnp.array(state)\n",
    "            state = state.at[..., :3].set(input_embed)\n",
    "            state1 = ca(state, task_embed, num_steps=num_steps)\n",
    "            output_grid1 = jnp.argmax(state1[..., :3], axis=-1).astype(int)\n",
    "            output_grid1 = output_grid1[:input_grid.shape[0], :input_grid.shape[1]]\n",
    "            state2 = ca(state, task_embed, num_steps=num_steps + 64)\n",
    "            output_grid2 = jnp.argmax(state2[..., :3], axis=-1).astype(int)\n",
    "            output_grid2 = output_grid2[:input_grid.shape[0], :input_grid.shape[1]]\n",
    "            outputs.append({\n",
    "                \"attempt_1\": output_grid1.tolist(),\n",
    "                \"attempt_2\": output_grid2.tolist()\n",
    "            })\n",
    "        submission[task_id] = outputs\n",
    "\n",
    "    with open('submission.json', 'w') as f:\n",
    "        json.dump(submission, f)\n",
    "\n",
    "test_challenges_path = '/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json'\n",
    "prepare_submission(ca, test_challenges_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
