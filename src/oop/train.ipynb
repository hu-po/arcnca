{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARC 2024 Neural Cellular Automata\n",
    "\n",
    "https://arcprize.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import mediapy\n",
    "import optax\n",
    "from cax.core.ca import CA\n",
    "from cax.core.perceive.depthwise_conv_perceive import DepthwiseConvPerceive\n",
    "from cax.core.perceive.kernels import grad_kernel, identity_kernel\n",
    "from cax.core.update.residual_update import ResidualUpdate\n",
    "from flax import nnx\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "channel_size = 32\n",
    "num_spatial_dims = 1\n",
    "num_kernels = 2\n",
    "hidden_size = 256\n",
    "cell_dropout_rate = 0.5\n",
    "\n",
    "batch_size = 8\n",
    "num_steps = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "ds_size = 128\n",
    "\n",
    "key = jax.random.key(seed)\n",
    "rngs = nnx.Rngs(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(\n",
    "    project='arc-2024-nca',\n",
    "    config={\n",
    "        'seed': seed,\n",
    "        'channel_size': channel_size,\n",
    "        'num_spatial_dims': num_spatial_dims,\n",
    "        'num_kernels': num_kernels,\n",
    "        'hidden_size': hidden_size,\n",
    "        'cell_dropout_rate': cell_dropout_rate,\n",
    "        'batch_size': batch_size,\n",
    "        'num_steps': num_steps,\n",
    "        'learning_rate': learning_rate,\n",
    "        'ds_size': ds_size,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install 1D-ARC dataset\n",
    "!git clone https://github.com/khalil-research/1D-ARC.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = \"./1D-ARC/dataset\"\n",
    "\n",
    "train_examples = []\n",
    "test_examples = []\n",
    "task_index_to_name = {}\n",
    "\n",
    "\n",
    "def process_example(example, task_index):\n",
    "\tinput_data = jnp.squeeze(jnp.array(example[\"input\"], dtype=jnp.int32))\n",
    "\toutput_data = jnp.squeeze(jnp.array(example[\"output\"], dtype=jnp.int32))\n",
    "\n",
    "\tassert input_data.shape == output_data.shape\n",
    "\n",
    "\tpad_size = ds_size - input_data.size\n",
    "\tpad_left, pad_right = pad_size // 2, pad_size - pad_size // 2\n",
    "\n",
    "\tinput_padded = jnp.pad(input_data, (pad_left, pad_right))\n",
    "\toutput_padded = jnp.pad(output_data, (pad_left, pad_right))\n",
    "\n",
    "\treturn jnp.expand_dims(\n",
    "\t\tjnp.concatenate([jnp.array([task_index], dtype=jnp.int32), input_padded, output_padded]), axis=-1\n",
    "\t)\n",
    "\n",
    "\n",
    "for task_index, task_name in enumerate(os.listdir(ds_path)):\n",
    "\ttask_index_to_name[task_index] = task_name\n",
    "\ttask_path = os.path.join(ds_path, task_name)\n",
    "\n",
    "\tfor task_file in os.listdir(task_path):\n",
    "\t\twith open(os.path.join(task_path, task_file)) as f:\n",
    "\t\t\tdata = json.load(f)\n",
    "\t\t\tfor split, examples in [(\"train\", train_examples), (\"test\", test_examples)]:\n",
    "\t\t\t\texamples.extend(process_example(ex, task_index) for ex in data[split])\n",
    "\n",
    "train_tasks = jnp.array(train_examples)\n",
    "test_tasks = jnp.array(test_examples)\n",
    "\n",
    "task_list = list(task_index_to_name.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_state(key):\n",
    "\t# Sample dataset\n",
    "\tsample = jax.random.choice(key, train_tasks)\n",
    "\n",
    "\t# Sample input and target\n",
    "\ttask_index, input, target = jnp.split(sample, indices_or_sections=[1, ds_size + 1])\n",
    "\n",
    "\t# Initialize state\n",
    "\tstate = jnp.zeros((ds_size, channel_size))\n",
    "\tstate = state.at[..., :1].set(input)\n",
    "\treturn state, target, task_index\n",
    "\n",
    "\n",
    "def init_state_test(key):\n",
    "\t# Sample dataset\n",
    "\tsample = jax.random.choice(key, test_tasks)\n",
    "\n",
    "\t# Sample input and target\n",
    "\ttask_index, input, target = jnp.split(sample, indices_or_sections=[1, ds_size + 1])\n",
    "\n",
    "\t# Initialize state\n",
    "\tstate = jnp.zeros((ds_size, channel_size))\n",
    "\tstate = state.at[..., :1].set(input)\n",
    "\treturn state, target, task_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceive = DepthwiseConvPerceive(channel_size, rngs, num_kernels=num_kernels, kernel_size=(3,))\n",
    "update = ResidualUpdate(\n",
    "\tnum_spatial_dims,\n",
    "\tchannel_size,\n",
    "\tnum_kernels * channel_size + 8,\n",
    "\t(hidden_size,),\n",
    "\trngs,\n",
    "\tcell_dropout_rate=cell_dropout_rate,\n",
    ")\n",
    "embed_input = nnx.Embed(num_embeddings=10, features=3, rngs=rngs)\n",
    "embed_task = nnx.Embed(num_embeddings=len(task_list), features=8, rngs=rngs)\n",
    "\n",
    "\n",
    "class EmbedCA(CA):\n",
    "\tembed_input: nnx.Embed\n",
    "\tembed_task: nnx.Embed\n",
    "\n",
    "\tdef __init__(self, perceive, update, embed_input, embed_task):\n",
    "\t\tsuper().__init__(perceive, update)\n",
    "\n",
    "\t\tself.embed_input = embed_input\n",
    "\t\tself.embed_task = embed_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = jnp.concatenate([identity_kernel(ndim=1), grad_kernel(ndim=1)], axis=-1)\n",
    "kernel = jnp.expand_dims(jnp.concatenate([kernel] * channel_size, axis=-1), axis=-2)\n",
    "perceive.depthwise_conv.kernel = nnx.Param(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = EmbedCA(perceive, update, embed_input, embed_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = nnx.state(ca, nnx.Param)\n",
    "print(\"Number of params:\", jax.tree.reduce(lambda x, y: x + y.size, params, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_sched = optax.linear_schedule(init_value=learning_rate, end_value=0.1 * learning_rate, transition_steps=2_000)\n",
    "\n",
    "optimizer = optax.chain(\n",
    "\toptax.clip_by_global_norm(1.0),\n",
    "\toptax.adam(learning_rate=lr_sched),\n",
    ")\n",
    "\n",
    "update_params = nnx.All(nnx.Param, nnx.PathContains(\"update\"))\n",
    "optimizer = nnx.Optimizer(ca, optimizer, wrt=update_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(state, target):\n",
    "\treturn jnp.mean(jnp.square(state[..., :3] - target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def loss_fn(ca, state, target, task_index):\n",
    "\t# Embed\n",
    "\tinput = state[..., 0]\n",
    "\tinput_embed = ca.embed_input(jnp.asarray(input, dtype=jnp.int32))\n",
    "\ttask_embed = ca.embed_task(jnp.asarray(task_index, dtype=jnp.int32))\n",
    "\tstate = state.at[..., :3].set(input_embed)\n",
    "\n",
    "\ttarget_embed = ca.embed_input(jnp.asarray(target[..., 0], dtype=jnp.int32))\n",
    "\n",
    "\tstate_axes = nnx.StateAxes({nnx.RngState: 0, ...: None})\n",
    "\tstate = nnx.split_rngs(splits=batch_size)(\n",
    "\t\tnnx.vmap(\n",
    "\t\t\tlambda ca, state, task_embed: ca(state, task_embed, num_steps=num_steps),\n",
    "\t\t\tin_axes=(state_axes, 0, 0),\n",
    "\t\t)\n",
    "\t)(ca, state, task_embed)\n",
    "\n",
    "\tloss = mse(state, target_embed)\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def train_step(ca, optimizer, key):\n",
    "\tkeys = jax.random.split(key, batch_size)\n",
    "\tstate, target, task_index = jax.vmap(init_state)(keys)\n",
    "\n",
    "\tloss, grad = nnx.value_and_grad(loss_fn, argnums=nnx.DiffState(0, update_params))(ca, state, target, task_index)\n",
    "\toptimizer.update(grad)\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_steps = 8_192\n",
    "print_interval = 128\n",
    "\n",
    "pbar = tqdm(range(num_train_steps), desc=\"Training\", unit=\"train_step\")\n",
    "losses = []\n",
    "\n",
    "for i in pbar:\n",
    "\tkey, subkey = jax.random.split(key)\n",
    "\tloss = train_step(ca, optimizer, subkey)\n",
    "\tlosses.append(loss)\n",
    "\n",
    "\tif i % print_interval == 0 or i == num_train_steps - 1:\n",
    "\t\tavg_loss = sum(losses[-print_interval:]) / len(losses[-print_interval:])\n",
    "\t\tpbar.set_postfix({\"Average Loss\": f\"{avg_loss:.6f}\"})\n",
    "\t\twandb.log({'average_loss': avg_loss, 'step': i})\n",
    "\twandb.log({'loss': loss, 'step': i})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "keys = jax.random.split(subkey, 8)\n",
    "state_init, target, task_index = jax.vmap(init_state_test)(keys)\n",
    "\n",
    "input = state_init[..., 0]\n",
    "input_embed = ca.embed_input(jnp.asarray(input, dtype=jnp.int32))\n",
    "task_embed = ca.embed_task(jnp.asarray(task_index, dtype=jnp.int32))\n",
    "state_init = state_init.at[..., :3].set(input_embed)\n",
    "\n",
    "state_axes = nnx.StateAxes({nnx.RngState: 0, ...: None})\n",
    "state = nnx.split_rngs(splits=batch_size)(\n",
    "\tnnx.vmap(\n",
    "\t\tlambda ca, state, task_embed: ca(state, task_embed, num_steps=num_steps, all_steps=True),\n",
    "\t\tin_axes=(state_axes, 0, 0),\n",
    "\t)\n",
    ")(ca, state_init, task_embed)\n",
    "\n",
    "state_rgb = jnp.concatenate([jnp.expand_dims(state_init[..., :3], axis=1), state[..., :3]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = [task_list[int(jnp.squeeze(task_index))] for task_index in task_index]\n",
    "mediapy.show_images(state_rgb, titles=task_name, width=256, height=256)\n",
    "state_rgb_np = jax.device_get(state_rgb)\n",
    "wandb.log({\n",
    "    \"examples\": [\n",
    "        wandb.Image(\n",
    "            state_rgb_np[i],\n",
    "            caption=f\"Task: {task_name[i]}\"\n",
    "        ) for i in range(len(state_rgb_np))\n",
    "    ]\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
